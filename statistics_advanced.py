# -*- coding: utf-8 -*-
"""STATISTICS ADVANCED.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EsFI7IpqjiHeqwVvP-AMph-50LwyVc_i

# **Q1. What is a random variable in probability theory?**
A random variable is a numerical outcome of a random phenomenon. It assigns values to outcomes in a sample space. Random variables can be discrete (countable outcomes) or continuous (infinite outcomes). For example, tossing a coin results in a discrete variable with two outcomes, while measuring height gives a continuous variable. Random variables allow us to use mathematical tools for analysis and prediction in statistics and probability.

# **Q2. What are the types of random variables?**
There are two main types of random variables: discrete and continuous.

Discrete random variables have countable outcomes (e.g., number of students).

Continuous random variables have infinite possible values within a range (e.g., weight, height).
Each type has its own distribution functions and statistical properties. Understanding their differences helps in selecting appropriate probability models and statistical tests for analyzing real-world data.

# **Q3. What is the difference between discrete and continuous distributions?**
Discrete distributions represent probabilities for countable outcomes (e.g., dice rolls), using probability mass functions (PMFs).
Continuous distributions model infinite outcomes over an interval (e.g., height), using probability density functions (PDFs).
The key difference is that discrete distributions assign exact probabilities to values, while continuous ones give probabilities over ranges. Each has unique applications in fields like quality control, finance, and biology.

# **Q4. What are probability distribution functions (PDF)?**
A Probability Distribution Function (PDF) describes the likelihood of different outcomes in a distribution.

For discrete variables, it's called the Probability Mass Function (PMF).

For continuous variables, PDF represents the density of probability across intervals.
The area under the PDF curve equals 1, indicating total probability. It’s essential for understanding data behavior and calculating the likelihood of events within a given range.

# **Q5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?**
The Cumulative Distribution Function (CDF) gives the probability that a random variable takes a value less than or equal to a certain number.
In contrast, the PDF gives the probability density at a specific point (continuous) or value (discrete).
CDF is always increasing and ranges from 0 to 1. It provides a cumulative view of probability, useful for percentile calculations and understanding probability accumulation.

# **Q6. What is a discrete uniform distribution?**
A Discrete Uniform Distribution is one where each outcome in a finite sample space has equal probability.
For example, rolling a fair six-sided die gives each number (1–6) a probability of 1/6.
The distribution is defined by two values: the smallest (a) and largest (b) integers in the range. It’s useful in simulations, gaming, and modeling equally likely outcomes.

# **Q7. What are the key properties of a Bernoulli distribution?**
A Bernoulli distribution models a single trial with only two outcomes: success (1) and failure (0).
It has one parameter, p, which represents the probability of success.
Key properties include:

Mean = p

Variance = p(1 - p)
This distribution is the building block for the binomial distribution and is widely used in binary classification and success-failure experiments.

# **Q8. What is the binomial distribution, and how is it used in probability?**
The Binomial distribution describes the number of successes in n independent Bernoulli trials with success probability p.
Used when each trial has only two outcomes (success/failure), and trials are identical.
Example: Probability of getting 3 heads in 5 coin tosses.
It helps in quality control, risk assessment, and clinical trial analysis. The mean is np, and variance is np(1–p).

# **Q9. What is the Poisson distribution and where is it applied?**
The Poisson distribution models the number of times an event occurs in a fixed interval of time or space, assuming events are independent and occur at a constant average rate.
Example: Number of calls received in an hour.
It’s used in queuing systems, reliability engineering, and traffic analysis.
Mean and variance are both equal to λ (lambda), the average rate of occurrence.

# **Q10. What is a continuous uniform distribution?**
A Continuous Uniform Distribution describes equally likely outcomes within a continuous interval [a, b].
Each value in the interval has the same probability density, defined by the formula:
f(x) = 1 / (b - a) for a ≤ x ≤ b.
It’s used in simulations and random sampling when all intervals are equally likely.
The mean is (a + b)/2 and variance is (b - a)² / 12.               
# **Q11. What are the characteristics of a normal distribution?**
A normal distribution is a symmetric, bell-shaped curve where most data points lie near the mean.
Key characteristics:

Mean = Median = Mode

Symmetrical about the mean

Follows the Empirical Rule (68%-95%-99.7%)

Defined by two parameters: mean (μ) and standard deviation (σ)
It is used widely in natural and social sciences to model real-world phenomena like heights, weights, and IQ scores.

# **Q12. What is the standard normal distribution, and why is it important?**
The standard normal distribution is a normal distribution with mean = 0 and standard deviation = 1.
It’s important because it standardizes different normal distributions for easy comparison using Z-scores.
It allows statisticians to compute probabilities and percentiles without recalculating each time.
It's widely used in hypothesis testing, quality control, and confidence intervals to assess how far a value is from the mean.

#**Q13. What is the Central Limit Theorem (CLT), and why is it critical in statistics?**
The Central Limit Theorem states that the distribution of sample means approaches a normal distribution as sample size increases, regardless of population distribution.
It’s critical because it justifies using normal probability tools on sample data.
CLT allows estimation of population parameters, confidence intervals, and hypothesis testing, making it foundational in inferential statistics.

#**Q14. How does the Central Limit Theorem relate to the normal distribution?**
The Central Limit Theorem explains why sample means from any distribution will follow a normal distribution, provided the sample size is large enough (n ≥ 30 is typical).
This makes the normal distribution a universal tool in statistics.
It enables us to use Z-scores, compute probabilities, and perform statistical testing even when the original data isn’t normally distributed.

#**Q15. What is the application of Z statistics in hypothesis testing?**
Z-statistics are used in hypothesis testing to determine how far a sample mean is from the population mean in standard deviation units.
If the Z-score lies beyond a critical value, the null hypothesis is rejected.
Z-tests are applicable when sample size is large (n ≥ 30) and population variance is known.
They're used in quality testing, medical trials, and comparing sample results to known benchmarks.

#**Q16. How do you calculate a Z-score, and what does it represent?**
The Z-score is calculated as:
Z = (X – μ) / σ
Where:

X = data point

μ = population mean

σ = population standard deviation

It represents how many standard deviations a data point is from the mean.
A Z-score helps assess extremeness of a value.
For example, Z = 2 means the value is 2 standard deviations above the mean.

#**Q17. What are point estimates and interval estimates in statistics?**
A point estimate gives a single value as an estimate of a population parameter (e.g., sample mean).

An interval estimate provides a range of values, often in the form of a confidence interval, within which the parameter is expected to lie.
Point estimates are more precise but less informative.
Interval estimates offer more reliability by accounting for sample variability and uncertainty.

#**Q18. What is the significance of confidence intervals in statistical analysis?**
Confidence intervals provide a range of values that likely contain the population parameter.
They quantify uncertainty in estimation and help assess the reliability of a sample statistic.
For example, a 95% confidence interval suggests that 95 out of 100 intervals would contain the true mean.
Used widely in research, economics, and medicine, they guide decision-making and hypothesis testing.

#**Q19. What is the relationship between a Z-score and a confidence interval?**
A Z-score defines how far a point lies from the mean, while a confidence interval uses Z-scores to create a range around the sample mean.
For example, in a 95% confidence interval, the Z-score is ±1.96.
Z-scores help calculate margin of error in the confidence interval formula:
CI = mean ± Z × (σ/√n)
Thus, Z-scores form the basis for building confidence intervals.

#**Q20. How are Z-scores used to compare different distributions?**
Z-scores standardize different datasets, converting values to a common scale with mean = 0 and standard deviation = 1.
This allows comparison across distributions with different units or spreads.
For example, a Z-score of 2 in test A and 1.5 in test B shows test A score is relatively better.
Z-scores help in identifying outliers and making fair comparisons across groups or experiments.

#**Q21. What are the assumptions for applying the Central Limit Theorem?**
Key assumptions for the Central Limit Theorem include:

Samples must be random and independent.

The sample size should be sufficiently large (usually n ≥ 30).

Population variance should be finite.

Samples must come from the same population.
These ensure that the sampling distribution of the mean approximates a normal distribution, enabling accurate statistical inference.

#**Q22. What is the concept of expected value in a probability distribution?**
The expected value is the long-run average or mean of a random variable’s outcomes, weighted by their probabilities.
For a discrete variable:
E(X) = Σ[x × P(x)]
It provides the theoretical center of the distribution and helps in decision-making under uncertainty.
For example, in games or investments, expected value predicts average gain or loss over time.

#**Q23. How does a probability distribution relate to the expected outcome of a random variable?**
A probability distribution describes all possible values a random variable can take and their probabilities.
The expected outcome is derived from this distribution as a weighted average of all values.
In simple terms, it’s the "center" of the distribution and represents what we expect in the long run.
This connection is crucial for predictions, simulations, and statistical inference.

# **Q1. Write a Python program to generate a random variable and display its value.**
"""

import random

# Generate a random integer between 1 and 100
random_variable = random.randint(1, 100)
print("Random Variable:", random_variable)

"""# **Q2. Generate a discrete uniform distribution using Python and plot the probability mass function (PMF).**"""

import matplotlib.pyplot as plt
import numpy as np

# Discrete uniform distribution from 1 to 6 (like a die)
values = np.arange(1, 7)
pmf = [1/6] * 6

plt.bar(values, pmf, color='skyblue')
plt.title("PMF of Discrete Uniform Distribution (Die Roll)")
plt.xlabel("Value")
plt.ylabel("Probability")
plt.xticks(values)
plt.grid(True)
plt.show()

"""# **Q3. Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution.**"""

def bernoulli_pdf(p, x):
    if x == 0:
        return 1 - p
    elif x == 1:
        return p
    else:
        return 0

# Example
p = 0.7
print("P(X=0):", bernoulli_pdf(p, 0))
print("P(X=1):", bernoulli_pdf(p, 1))

"""# **Q4. Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram.**"""

import numpy as np
import matplotlib.pyplot as plt

n, p = 10, 0.5
samples = np.random.binomial(n, p, 1000)

plt.hist(samples, bins=np.arange(0, 12)-0.5, density=True, color='orange', edgecolor='black')
plt.title("Binomial Distribution (n=10, p=0.5)")
plt.xlabel("Number of Successes")
plt.ylabel("Probability")
plt.grid(True)
plt.show()

"""# **Q5. Create a Poisson distribution and visualize it using Python.**"""

from scipy.stats import poisson

mu = 3  # average rate
x = np.arange(0, 10)
pmf = poisson.pmf(x, mu)

plt.bar(x, pmf, color='green', edgecolor='black')
plt.title("Poisson Distribution (λ=3)")
plt.xlabel("Number of Events")
plt.ylabel("Probability")
plt.grid(True)
plt.show()

"""#**Q6. Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete uniform distribution.**

"""

import numpy as np
import matplotlib.pyplot as plt

# Discrete uniform distribution from 1 to 6
x = np.arange(1, 7)
cdf = np.cumsum([1/6]*6)

plt.step(x, cdf, where='mid', color='purple')
plt.title("CDF of Discrete Uniform Distribution (Die Roll)")
plt.xlabel("Value")
plt.ylabel("Cumulative Probability")
plt.grid(True)
plt.show()

"""#**Q7. Generate a continuous uniform distribution using NumPy and visualize it.**"""

import numpy as np
import matplotlib.pyplot as plt

data = np.random.uniform(0, 1, 1000)

plt.hist(data, bins=20, color='teal', edgecolor='black', density=True)
plt.title("Histogram of Continuous Uniform Distribution (0 to 1)")
plt.xlabel("Value")
plt.ylabel("Density")
plt.grid(True)
plt.show()

"""#**Q8. Simulate data from a normal distribution and plot its histogram.**"""

data = np.random.normal(loc=0, scale=1, size=1000)

plt.hist(data, bins=30, color='steelblue', edgecolor='black', density=True)
plt.title("Histogram of Normal Distribution (mean=0, std=1)")
plt.xlabel("Value")
plt.ylabel("Density")
plt.grid(True)
plt.show()

"""
#**Q9. Write a Python function to calculate Z-scores from a dataset and plot them.**
"""

from scipy.stats import zscore

data = np.random.normal(50, 10, 100)
z_scores = zscore(data)

plt.plot(z_scores, 'bo')
plt.axhline(0, color='red', linestyle='--')
plt.title("Z-scores of Dataset")
plt.xlabel("Index")
plt.ylabel("Z-score")
plt.grid(True)
plt.show()

"""# **Q10. Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution.**"""

import numpy as np
import matplotlib.pyplot as plt

# Exponential distribution (non-normal)
population = np.random.exponential(scale=2.0, size=100000)
sample_means = []

# Draw 1000 samples of size 30
for _ in range(1000):
    sample = np.random.choice(population, 30)
    sample_means.append(np.mean(sample))

plt.hist(sample_means, bins=30, density=True, color='lightcoral', edgecolor='black')
plt.title("Central Limit Theorem - Sampling Means (n=30)")
plt.xlabel("Sample Mean")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

"""#**Q11. Simulate multiple samples from a normal distribution and verify the Central Limit Theorem.**

"""

import numpy as np
import matplotlib.pyplot as plt

# Simulate multiple sample means
population = np.random.normal(loc=50, scale=15, size=100000)
sample_means = [np.mean(np.random.choice(population, 50)) for _ in range(1000)]

plt.hist(sample_means, bins=30, density=True, color='lightgreen', edgecolor='black')
plt.title("Central Limit Theorem Verification")
plt.xlabel("Sample Mean")
plt.ylabel("Density")
plt.grid(True)
plt.show()

"""#**Q12. Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1).**"""

from scipy.stats import norm

x = np.linspace(-4, 4, 1000)
pdf = norm.pdf(x, 0, 1)

plt.plot(x, pdf, color='darkblue')
plt.title("Standard Normal Distribution (μ=0, σ=1)")
plt.xlabel("Z")
plt.ylabel("Density")
plt.grid(True)
plt.show()

"""#**Q13. Generate random variables and calculate their corresponding probabilities using the binomial distribution.**

"""

from scipy.stats import binom

n, p = 10, 0.5
x = np.arange(0, 11)
pmf = binom.pmf(x, n, p)

plt.bar(x, pmf, color='orange', edgecolor='black')
plt.title("Binomial Distribution PMF (n=10, p=0.5)")
plt.xlabel("Number of Successes")
plt.ylabel("Probability")
plt.grid(True)
plt.show()

"""#**Q14. Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal distribution.**"""

from scipy.stats import norm

x = 72
mean = 60
std = 10
z = (x - mean) / std

print("Z-score:", z)
prob = norm.cdf(z)
print("Probability (P(X ≤ 72)):", prob)

"""#**Q15. Implement hypothesis testing using Z-statistics for a sample dataset.**"""

import numpy as np
from scipy.stats import norm

# Sample values
sample = np.random.normal(loc=52, scale=5, size=40)
sample_mean = np.mean(sample)
pop_mean = 50
std = 5

z = (sample_mean - pop_mean) / (std / np.sqrt(len(sample)))
p_value = 1 - norm.cdf(z)

print("Sample Mean:", sample_mean)
print("Z-score:", z)
print("P-value:", p_value)

"""
#**Q16. Create a confidence interval for a dataset using Python and interpret the result.**
"""

import numpy as np
from scipy.stats import norm

data = np.random.normal(100, 15, 50)
mean = np.mean(data)
std = np.std(data, ddof=1)
n = len(data)

z = 1.96  # For 95% confidence
margin_error = z * (std / np.sqrt(n))
ci_lower = mean - margin_error
ci_upper = mean + margin_error

print("95% Confidence Interval: (", round(ci_lower, 2), ",", round(ci_upper, 2), ")")

"""#**Q17. Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean.**"""

data = np.random.normal(60, 10, 100)
mean = np.mean(data)
std = np.std(data, ddof=1)
n = len(data)
z = 1.96

margin_error = z * (std / np.sqrt(n))
ci = (mean - margin_error, mean + margin_error)

print("Mean:", round(mean, 2))
print("95% Confidence Interval:", (round(ci[0], 2), round(ci[1], 2)))

"""#**Q18. Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution.**

"""

from scipy.stats import norm
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(-4, 4, 1000)
pdf = norm.pdf(x, 0, 1)

plt.plot(x, pdf, color='navy')
plt.title("PDF of Normal Distribution (μ=0, σ=1)")
plt.xlabel("x")
plt.ylabel("Density")
plt.grid(True)
plt.show()

"""
#**Q19. Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution.**
"""

from scipy.stats import poisson
import numpy as np
import matplotlib.pyplot as plt

mu = 4
x = np.arange(0, 11)
cdf = poisson.cdf(x, mu)

plt.step(x, cdf, where='mid', color='darkgreen')
plt.title("CDF of Poisson Distribution (λ=4)")
plt.xlabel("Number of Events")
plt.ylabel("Cumulative Probability")
plt.grid(True)
plt.show()

"""#**Q20. Simulate a random variable using a continuous uniform distribution and calculate its expected value.**"""

import numpy as np

a, b = 10, 20
data = np.random.uniform(a, b, 10000)
expected_value = np.mean(data)

print("Expected Value (approx):", round(expected_value, 2))

"""#**Q21. Write a Python program to compare the standard deviations of two datasets and visualize the difference.**"""

data1 = np.random.normal(50, 5, 100)
data2 = np.random.normal(50, 15, 100)

std1 = np.std(data1)
std2 = np.std(data2)

plt.hist(data1, bins=20, alpha=0.7, label='Std Dev = 5')
plt.hist(data2, bins=20, alpha=0.7, label='Std Dev = 15')
plt.legend()
plt.title("Comparison of Standard Deviations")
plt.xlabel("Value")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

print("Std Dev 1:", round(std1, 2))
print("Std Dev 2:", round(std2, 2))

"""#**Q22. Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution.**

"""

import numpy as np

data = np.random.normal(100, 20, 100)
data_range = np.max(data) - np.min(data)
q1 = np.percentile(data, 25)
q3 = np.percentile(data, 75)
iqr = q3 - q1

print("Range:", round(data_range, 2))
print("Interquartile Range (IQR):", round(iqr, 2))

"""#**Q23. Implement Z-score normalization on a dataset and visualize its transformation.**"""

from scipy.stats import zscore
import matplotlib.pyplot as plt

data = np.random.normal(100, 20, 100)
z_normalized = zscore(data)

plt.hist(z_normalized, bins=20, color='violet', edgecolor='black')
plt.title("Z-score Normalized Data")
plt.xlabel("Z-score")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()